---
- name: Installing platform
  hosts: rockstat
  become: yes
  vars_files:
    - vars/nginx.yml
  tasks:
    - name: Checking python interpreter
      assert:
        that: 
          - "ansible_python_interpreter == '/usr/bin/python3'"
        msg: "Required python 3. Details: https://docs.ansible.com/ansible/latest/reference_appendices/python_3_support.html"
      tags: ["always"]

      ##### ##### ##### ##### #####    Server configuration    ##### ##### ##### ##### ##### 
    - block:
      - name: Including Base Server role
        include_role:
          name: dr.server
        vars:
          drs_setup_user: yes
          drs_user: '{{support_user}}'
          drs_home_dir: "{{home_dir}}"
          drs_pub_key_file: '{{support_key_file}}'
          drs_disable_ipv6: "{{disable_ipv6}}"
          drs_extra_hosts: {home: "{{if_inner}}"}
      when: 'setup_server == True'
      tags: ['never', 'os', 'network', 'system', 'full_setup']


    ##### ##### ##### ##### #####    Docker server     ##### ##### ##### ##### ##### 
    - block:
      - name: Including Docker role
        include_role:
          name: dr.docker
        vars:
          drd_users:
          - "{{support_user}}"
          drd_create_network: yes
          drd_version: edge
          drd_net_name: '{{docker_net_name}}'
          drd_bind_ip: "{{docker_host_ip}}"
          drd_interface: '{{docker_interface}}'
          drd_net: '{{docker_net}}'
          drd_mtu: '1400'
      tags: ['never', 'docker', 'docker-server', 'system', 'full_setup']


    ##### ##### ##### ##### #####    Exposeur (UFW, iptables)    ##### ##### ##### ##### ##### 
    - block:
      - name: Including Exposeur role
        include_role:
          name: dr.exposeur
        vars:
          expo_reset_ufw: true
          expo_rules: '{{firewall_rules|flatten + host_firewall_rules|default([]) + group_firewall_rules|default([])}}'
          expo_expose_rules: '{{expose_rules|default([]) + host_expose_rules|default([]) + group_expose_rules|default([])}}'
      tags: ['never', 'firewall', 'network', 'system', 'full_setup']


    ##### ##### ##### ##### #####    Lets encrypt Certbot    ##### ##### ##### ##### ##### 
    - block:
      - name: Including LetsEncrypt role
        include_role:
          name: dr.letsencrypt
        vars:
          letsencrypt_domains_groups: '{{domains_ssl}}'
          letsencrypt_pause_services: ['nginx']
      when: "_setup_ssl == True and not _setup_ssl_wildcard | bool == True"
      tags: ['never', 'ssl', 'ssl-certbot']


    ##### ##### ##### ##### #####    Lets encrypt WildCard    ##### ##### ##### ##### ##### 

    - block:
      - name: Including LetsEncrypt AcmeDNS role
        include_role:
          name: dr.letsencrypt.wildcard.auto
        vars:
          _r_acmesh_config_dir: "{{dirs.acmesh}}/config"
          _r_acmedns_config_dir: "{{dirs.acmedns}}/config"
          _r_acmedns_data_dir: "{{dirs.acmedns}}/data"
          _r_acmesh_host_cert_root: "{{_ssl_cert_dir}}"
          _r_acmedns_host: "{{_acmedns_endpoint}}"
          _r_acmedns_api: "http://{{_r_acmedns_host}}:19943"
          _r_acmedns_ns1_ip: "{{_challenge_ns1|default('0.0.0.0')}}"
          _r_acmedns_ns2_ip: "{{_challenge_ns2|default('0.0.0.0')}}"
          _r_acmedns: "{{_acmedns_setup}}"
          _r_domains: "{{_ssl_certs}}"
      when: "_setup_ssl == True and _setup_ssl_wildcard | bool == True"
      tags: ['never', 'ssl', 'ssl-wildcard']

    - service:
        name: nginx
        state: restarted
      failed_when: no
      tags: ['never', 'ssl', 'ssl-wildcard']


    ##### ##### ##### ##### #####    Nginx    ##### ##### ##### ##### ##### 
    - block:
      - name: Including Nginx role
        include_role:
          name: jdauphant.nginx
        vars:
          nginx_official_repo: no
          keep_only_specified: yes
          nginx_http_params: '{{_nginx_http_params}}'
          nginx_sites: "{{_nginx_sites|combine(_nginx_sites_extra|default({}))}}"
          nginx_auth_basic_files:
            common: "{{ common_users|flatten }}"
          nginx_configs:
            upgrade: '{{_nginx_proto_upgrade}}'
            gzip: '{{_nginx_gzip_params}}'
            proxy: '{{_nginx_proxy_params + _nginx_proxy_params_extra|default([])}}'
            upstream: '{{_nginx_upstreams}}'
            ssl: '{{_nginx_ssl_params}}'
      vars:
        # local_config: "{{ansible_local.config|default({})}}"
        # local_general: "{{local_config.general|default({})}}"
        common_users:
          - "admin:{{_local_config.admin_password}}"
          # - "{{local_general.users}}"
      when: "setup_nginx == True"
      tags: ['never', 'nginx', 'system', 'full_setup']


    ##### ##### ##### ##### #####    Splash screen    ##### ##### ##### ##### ##### 
    - block:
      - name: "Creating directory for splash screen"
        file:
          path: "{{dirs.splash}}"
          state: directory
        when: 'dr_dir is defined'

      - name: Cloning splash screen repo
        git:
          repo: "{{repos.splash}}"
          accept_hostkey: yes
          dest: "{{dirs.splash}}"
      tags: ['splash', 'ppart', 'band', 'static', 'full_setup']


    ##### ##### ##### ##### #####    Netdata    ##### ##### ##### ##### ##### 
    - block:
      - name: Including Netdata role
        include_role:
          name: dr.netdata
        vars:
          drn_allow:
            dashboard_from: "*"
            badges_from: "*"
            conf_from: "*"
            connections_from: "*"
            streaming_from: "*"
          drn_stream: '{{netdata_stream_config|default({})}}'
          drn_backend: '{{netdata_backend_config|default({})}}'
          drn_bind_to: "{{if_inner}}"
      tags: ['never', 'netdata', 'system', 'full_setup']


    ##### ##### ##### ##### #####    Clickhouse    ##### ##### ##### ##### ##### 
    - block: 
      - name: Including ClickHouse role
        include_role:
          name: AlexeySetevoi.clickhouse
        vars:
          nets: 
          ifaces: 
          clickhouse_users_custom: '{{ch_users|default([])}}'
          clickhouse_listen_host_default: ['127.0.0.1', "{{if_inner}}"] # '::1', 
          clickhouse_networks_default: ['127.0.0.1', "{{docker_net}}"] # '::1', 
          clickhouse_dbs_custom: [{name: '{{ch_db}}'}]
          clickhouse_path_data: "{{dirs.clickhouse}}"
          clickhouse_path_tmp: "{{dirs.clickhouse_tmp}}"
        retries: 3
        delay: 3
      tags: ['never', 'clickhouse', 'clickhouse-server', 'system', 'full_setup']


    ##### ##### ##### ##### #####    Clickhouse Proxy    ##### ##### ##### ##### ##### 
    - block:
      - name: CHProxy setup
        debug: msg="role begin"
      - name: Including ClickHouse proxy role
        include_role: 
          name: chproxy
        vars:
          chproxy_docker_bind: "{{if_inner}}:{{ports.chproxy.0}}:{{ports.chproxy.1}}"
          chproxy_def_node: "{{if_inner}}:{{ports.clickhouse.0}}"
          chproxy_clusters: "{{hst_chproxy_clusters|default([])}}"
          chproxy_docker_net: "{{docker_net_name}}"
          chproxy_users: "{{_chproxy_users|default([])}}"
          chproxy_allowed_networks: "{{_chproxy_allow_from|default([]) + _group_chproxy_allow_from|default([])}}"
          chproxy_build_path: "{{build_dir}}/chproxy"
      tags: ['never', 'clickhouse-proxy', 'chproxy', 'pservice', 'docker', 'docker-container', 'full_setup']


    ##### ##### ##### ##### #####    Redis server    ##### ##### ##### ##### ##### 
    - name: Redis setup
      block:
      - name: Including Docker container role for Redis server
        include_role:
          name: dr.docker-container
        vars:
          drdc_name: "redis"
          drdc_image: "redis:4-alpine"
          drdc_network: '{{docker_net_name}}'
          drdc_hosts: "{{docker_etc_hosts}}"
          drdc_memory_limit: '200m'
          drdc_nocache: "{{dock_no_cache}}"
          drdc_volumes: ["{{dirs.redis}}:/data"]
          drdc_ports: ["{{if_inner}}:{{ports.redis.0}}:{{ports.redis.1}}"]
      tags: ['never', 'redis', 'docker', 'system', 'docker-container', 'full_setup']


    ##### ##### ##### ##### #####    Logspout    ##### ##### ##### ##### ##### 
    - name: Logspout with Loggly streaming
      block:
      - debug:
          msg: "Using {{_logspout_target}} target"
      - name: Including Docker container role for Logspout
        include_role:
          name: dr.docker-container
        vars:
          endpoints:
            loggly: "syslog+tcp://{{_loggly_hostname}}"
            papertrail: "syslog+tls://{{_papertrail_hostname}}"
          env:
            common:
              SYSLOG_HOSTNAME: "{{hostname}}"
              TAIL: 100
            loggly:
              SYSLOG_STRUCTURED_DATA: "{{_loggly_api_key}}@41058 tag=\"Logspout\""
          drdc_name: "logspout"
          drdc_image: "gliderlabs/logspout"
          drdc_network: '{{docker_net_name}}'
          drdc_hosts: "{{docker_etc_hosts}}"
          drdc_nocache: "{{dock_no_cache}}"
          drdc_cmd: "{{endpoints[_logspout_target]}}"
          drdc_volumes:
            - /var/run/docker.sock:/var/run/docker.sock
          drdc_env: "{{ {}|combine(env.common, env[_logspout_target]|default({})) }}"
      when: "_logspout_enabled|default(0) == True"
      tags: ['never', 'logspout', 'logger', 'monitoring', 'docker', 'system', 'docker-container', 'full_setup']


    ##### ##### ##### ##### #####    Anaconda    ##### ##### ##### ##### ##### 
    - block:
      - name: Anaconda setup
        debug: msg="bind to {{if_inner}}:{{ports.jupyter.0}}:{{ports.jupyter.1}}"
      - name: Including Docker container role for Anaconda
        include_role:
          name: dr.docker-container
        vars:
          conda_list: "{{jup_with_conda_def + jup_with_conda}}"
          pip_list: "{{jup_with_pip_def + jup_with_pip}}"
          cmd_parts:
            - "{{conda_list|length > 0 and ('conda install -y ' + conda_list|join(' ') + ' && ') or ''}}"
            - "{{pip_list|length > 0 and ('pip install ' + pip_list|join(' ') + ' && ') or ''}}"
            - "/opt/conda/bin/conda install jupyter -y --quiet && "
            - "/opt/conda/bin/jupyter notebook --notebook-dir=/opt/notebooks"
            - "--ip='*' --port=8888 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.allow_origin='*'"
          drdc_name: 'anaconda'
          drdc_image: "continuumio/anaconda3"
          drdc_network: '{{docker_net_name}}'
          drdc_nocache: "{{dock_no_cache}}"
          drdc_hosts: "{{docker_etc_hosts}}"
          drdc_memory_limit: '{{anaconda_mem_limit}}'
          drdc_cmd: "/bin/bash -c \"{{cmd_parts|join(' ')}}\""
          drdc_labels: "{{docker_band_lbls}}"
          drdc_env: "{{containers_env}}"
          drdc_volumes: 
            - '{{dirs.notebooks}}:/opt/notebooks'
          drdc_ports: ["{{if_inner}}:{{ports.jupyter.0}}:{{ports.jupyter.1}}"]
      when: 'setup_jupyter == True'
      tags: ['never', 'anaconda', 'jupyter', 'pservice', 'docker', 'docker-container', 'full_setup']


    ##### ##### ##### ##### #####    Grafana    ##### ##### ##### ##### ##### 
    - block:
      - name: Creating Grafana datadir
        file:
          state: directory
          path: "{{dirs.grafana_data}}"
          owner: 472 # grafana container ids
          group: 472

      - docker_container:
          name: grafana
          hostname: grafana
          image: rockstat/grafana
          labels: "{{docker_band_lbls}}"
          networks: [ { name: "{{docker_net_name}}" } ]
          etc_hosts: "{{docker_etc_hosts}}"
          restart: yes
          memory: "300m"
          ports:
            - "{{if_inner}}:{{ports.grafana.0}}:{{ports.grafana.1}}"
          volumes:
            - '{{dirs.grafana_data}}:/var/lib/grafana'
        tags: ['never', 'grafana', 'pservice', 'docker', 'docker-container', 'full_setup']



    ##### ##### ##### ##### #####    Dashboard    ##### ##### ##### ##### ##### 
    - block:
      - name: Including Static service role for Dashboars
        include_role:
          name: dr.static-service
        vars:
          dr_name: dashboard
          dr_dir: '{{dirs.dashboard}}'
          dr_repo: "{{repos.dashboard}}"
      tags: ['dashboard', 'ppart', 'band', 'static', 'full_setup']


    ##### ##### ##### ##### #####    Band Director    ##### ##### ##### ##### ##### 
    - block:
      - docker_image:
          name: rockstat/band-base-py
          force: yes

      - name: Cloning Band-set repo
        git:
          repo: "{{repos.band_set}}"
          dest: "{{dirs.band_set}}"

      - name: Including Docker container role for Director service
        docker_container:
          name: director
          hostname: director
          image: rockstat/director
          labels: "{{docker_band_lbls}}"
          ports: [ "{{if_inner}}:{{ports.director.0}}:{{ports.director.1}}" ]
          networks: [ { name: "{{docker_net_name}}" } ]
          etc_hosts: "{{docker_etc_hosts}}"
          env: "{{ director_env|combine(containers_env, director_env_extra|default({})) }}"
          pull: yes
          restart: yes
          memory: "300m"
          volumes:
            - "{{dirs.band_set}}:/images/band_set:ro"
            - "{{dirs.rockme_set}}:/images/rockme_set:ro"
            - "{{dirs.director_data}}:/data" # containers configs
            # - "{{dirs.band}}:/images/band_base_py:ro"
            - "{{dirs.user_images}}:/images/user:ro"
            - "/var/run/docker.sock:/var/run/docker.sock"
      tags: ['band', 'ppart', 'docker', 'director', 'docker-container', 'full_setup']

    ##### ##### ##### ##### #####    Theia    ##### ##### ##### ##### ##### 
    - block:
      - name: Creating User Images Directory
        file: state=directory path={{dirs.user_images}} owner=473 group=473
      - name: Creating User Workspace Directory
        file: state=directory path={{dirs.workspace}} owner=473 group=473
      - name: Cloning Theia repo
        git:
          repo: "{{repos.theia}}"
          dest: "{{build_path}}"
      - name: Creating theia cointainer
        docker_container:
          name: theia
          hostname: theia
          image: rockstat/theia-ide
          labels: "{{docker_band_lbls}}"
          ports: [ "{{if_inner}}:{{ports.theia.0}}:{{ports.theia.1}}" ]
          networks: [ { name: "{{docker_net_name}}" } ]
          etc_hosts: "{{docker_etc_hosts}}"
          env: "{{containers_env}}"
          pull: yes
          restart: yes
          memory: "2g"
          volumes:
            - "{{dirs.workspace}}:{{workspace}}/:cached"
            - "{{dirs.user_images}}:{{workspace}}/my_images:cached"
            # - "{{dirs.band}}:{{workspace}}/sources_ro/band:ro"
            - "{{dirs.band_set}}:{{workspace}}/sources_ro/band_set:ro"
            - "{{dirs.band_set}}/__skeletons:{{workspace}}/sources_ro/skeletons:ro"
            - "{{dirs.rockme_set}}:{{workspace}}/sources_ro/rockme_set:ro"
      - name: Copying bootstrap files
        command: 'cp -nR {{build_path}}/bootstrap/.theia {{dirs.workspace}}/'
      vars:
        workspace: "/home/theia/project"
        build_path: "{{build_dir}}/theia"
      when: 'setup_theia == True'
      tags: ['theia', 'pservice', 'band', 'docker', 'docker-container', 'full_setup']


    ##### ##### ##### ##### #####    Front    ##### ##### ##### ##### ##### 
    - block:
      - name: Running docker container for Front service
        docker_container:
          name: front
          hostname: front
          image: "rockstat/front"
          labels: "{{docker_band_lbls}}"
          ports: 
            - "{{if_inner}}:{{ports.front.0}}:{{ports.front.1}}"
            - "{{if_inner}}:{{ports.front_ws.0}}:{{ports.front_ws.1}}"
          networks: [ { name: "{{docker_net_name}}" } ]
          etc_hosts: "{{docker_etc_hosts}}"
          env: "{{env|combine(containers_env, front_env_extra|default({}) )}}"
          pull: yes
          restart: yes
          memory: "300m"
          volumes:
            - "{{dirs.front_custom_config}}:/app/config/custom"
      vars:
        env: {}
      tags: ['front', 'ppart', 'rockme', 'docker', 'docker-container', 'full_setup']


    ##### ##### ##### ##### #####    ClickHouse migrations    ##### ##### ##### ##### ##### 
    # - name: Including ClickHouse maintain role
    #   block:
    #   - import_tasks: tasks/ch_migrate.yml
    #     vars:
    #       operate_db: "{{ch_db}}"
    #       operate_host: "127.0.0.1"
    #       migrations_path: clickhouse_migrations
    #   tags: ['never', 'chmigrate']


    ##### ##### ##### ##### #####    ClickHouse Writer    ##### ##### ##### ##### ##### =
    - block:
      - name: Running docker container for ClickHouse Writer service
        docker_container:
          name: chwriter
          hostname: chwriter
          image: "rockstat/chwriter"
          labels: "{{docker_band_lbls}}"
          networks: [ { name: "{{docker_net_name}}" } ]
          etc_hosts: "{{docker_etc_hosts}}"
          env: "{{env|combine(containers_env)}}"
          pull: yes
          restart: yes
          memory: "300m"
          volumes:
            - "{{dirs.chwriter_custom_config}}:/app/config/custom"
            - "{{dirs.chwriter_emergency}}:/app/emergency"
      vars:
        env: {}
      tags: ['chwriter', 'ppart', 'rockme', 'docker', 'docker-container', 'full_setup']

    ##### ##### ##### ##### #####    Heavyload    ##### ##### ##### ##### ##### 
    - block:
      - name: Including Docker container role for Heavyload service
        docker_container:
          name: heavyload
          hostname: heavyload
          image: "rockstat/heavyload"
          labels: "{{docker_band_lbls}}"
          networks: [ { name: "{{docker_net_name}}" } ]
          etc_hosts: "{{docker_etc_hosts}}"
          env: "{{env|combine(containers_env)}}"
          pull: yes
          restart: yes
          memory: "100m"
          volumes:
            - "{{dirs.uploads}}:/go/src/heavyload/upload"
          ports:
            - "{{if_inner}}:{{ports.heavyload.0}}:{{ports.heavyload.1}}"
      vars:
        env:
          WEBHOOK: "http://front:{{ports.front.1}}/upload/notify"
      tags: ['heavyload', 'docker', 'pservice', 'docker-container', 'full_setup']


    - import_tasks: tasks/setup_vpn_server.yml
      tags: ['never', 'ovpn-server']

    # - import_tasks: extensions/metrics_server.yml
    #   when: 'metrics_server == True'

    # - import_role:
    #     name: dr.openvpn-client
    #   vars:
    #     openvpnc_key: '{{s2s_vpn_key}}'
    #   when: s2s_vpn_connect is defined and s2s_vpn_connect == True and vpn_id is defined
    #   tags: ['s2s-ovpn-client', 's2s-ovpn']

